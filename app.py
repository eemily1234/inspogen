import streamlit as st
from gtts import gTTS
import requests
from PIL import Image
from io import BytesIO
import base64

st.set_page_config(page_title="InspoGen ä¸€é å¼ AI è²¼æ–‡ç”¢ç”Ÿå™¨", page_icon="ğŸŒŸ")
st.title("ğŸŒŸ InspoGen - ä¸€é å¼ AI å¤šæ¨¡æ…‹è²¼æ–‡ç”¢ç”Ÿå™¨")

# --- ä¸»é¡Œé¸æ“‡å€å¡Š ---
st.header("ğŸ“ Step 1ï¼šè¼¸å…¥ä¸»é¡Œèˆ‡é¢¨æ ¼")
topic = st.selectbox("é¸æ“‡ä¸»é¡Œ", ["å’–å•¡å»³", "æ—…è¡Œ", "é–±è®€", "ç©¿æ­", "æ—¥å¸¸ç”Ÿæ´»"])
style = st.selectbox("é¸æ“‡æ–‡é¢¨", ["ç™‚ç™’", "æç¬‘", "æ–‡é’", "æ¥µç°¡"])
tts_speed = st.selectbox("èªéŸ³èªé€Ÿ", ["æ­£å¸¸", "ç¨æ…¢", "å¿«é€Ÿ"])

# --- ç”¢æ–‡å€å¡Š ---
st.subheader("âœï¸ IG è²¼æ–‡å…§å®¹")
caption = ""
if st.button("ğŸ”® ç”¢ç”Ÿ IG è²¼æ–‡å…§å®¹"):
    prompt = f"è«‹ç”¨{style}çš„èªæ°£ï¼Œç‚ºã€Œ{topic}ã€å¯«ä¸€æ®µå¤§ç´„60å­—çš„IGè²¼æ–‡ï¼ŒåŠ å…¥ emojiã€‚"
    try:
        with st.spinner("AI ç”Ÿæˆä¸­ï¼Œè«‹ç¨å€™..."):
            res = requests.post(
                "https://api-inference.huggingface.co/models/google/flan-t5-base",
                headers={"Content-Type": "application/json"},
                json={"inputs": prompt},
                timeout=20
            )
            result = res.json()
            if isinstance(result, list) and "generated_text" in result[0]:
                caption = result[0]["generated_text"].strip()
            else:
                caption = f"é€™æ˜¯ä¸€æ®µæ¨¡æ“¬çš„ {style} é¢¨æ ¼ IG è²¼æ–‡ï¼Œä¸»é¡Œæ˜¯ã€Œ{topic}ã€ âœ¨ğŸ“·"
    except:
        caption = f"é€™æ˜¯ä¸€æ®µæ¨¡æ“¬çš„ {style} é¢¨æ ¼ IG è²¼æ–‡ï¼Œä¸»é¡Œæ˜¯ã€Œ{topic}ã€ âœ¨ğŸ“·"
    st.success("âœ… ç”¢ç”Ÿå®Œæˆ")
    st.write(caption)

    # èªéŸ³
    tts = gTTS(
        f"é€™æ®µè²¼æ–‡ä¸»é¡Œæ˜¯ã€Œ{topic}ã€ï¼Œæ–‡é¢¨æ˜¯ {style}ï¼Œå…§å®¹æ˜¯ï¼š" + caption,
        lang="zh",
        slow=True if tts_speed == "ç¨æ…¢" else False
    )
    tts.save("voice.mp3")
    st.audio("voice.mp3")
    with open("voice.mp3", "rb") as f:
        st.download_button("â¬‡ï¸ ä¸‹è¼‰èªéŸ³", f, file_name="voice.mp3")

# --- ç”¢åœ–å€å¡Š ---
st.header("ğŸ–¼ï¸ Step 2ï¼šè¼¸å…¥æè¿°ç”¢ç”Ÿé…åœ–")
desc = st.text_input("è«‹æè¿°ä½ æƒ³è¦çš„åœ–ç‰‡é¢¨æ ¼ï¼ˆä¾‹å¦‚ï¼šå¯æ„›æ’ç•«é¢¨çš„ä¸‹åˆèŒ¶å ´æ™¯ï¼‰")

if st.button("ğŸ¨ ç”Ÿæˆé…åœ–") and desc:
    st.info("åœ–ç‰‡ç”Ÿæˆä¸­ï¼Œè«‹ç¨å€™ç´„ 10ï½15 ç§’...")
    try:
        response = requests.post(
            "https://hf.space/embed/lambdal/text-to-image/api/predict",
            json={"data": [desc]},
            timeout=30
        )
        output = response.json()
        if output and "data" in output and len(output["data"]) > 0:
            base64_img = output["data"][0].split(",")[1]
            img_data = base64.b64decode(base64_img)
            image = Image.open(BytesIO(img_data))
            st.image(image, caption="âœ¨ AI ç”Ÿæˆåœ–ç‰‡")
            st.success("âœ… ç”Ÿæˆå®Œæˆï¼Œå¯å³éµå¦å­˜åœ–ç‰‡")
        else:
            st.error("âš ï¸ åœ–ç‰‡ç”¢ç”Ÿå¤±æ•—ï¼Œè«‹æ›´æ›æè¿°å…§å®¹å†è©¦")
    except:
        st.error("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œé‡è©¦")
